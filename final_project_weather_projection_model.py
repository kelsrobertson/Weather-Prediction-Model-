# -*- coding: utf-8 -*-
"""Final Project - Weather Projection Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wK3l8Mi3awJYwngCMI2DWgd9jVEnLEBs

<h1 style="color:red", text align='center';> ISAT 449: Data Science and Machine Learning
    
<h1 style="color: blue", text align='center';>Final Project:  Weather Projection

<h3 style="color: blue", text align='center';>Using Machine Learning tools and Weather Dataset from Kaggle

<h3 style="color: black", text align='center';>Predict Weather Conditions for 10 cities based on Temperature (C°), Humidity (%), Precipitation (mm), Wind Speed (kmh), and Date_Time.

<h4 text align='center'> Kelsey Robertson and Allie Zombron </h4>
    
<img src="images/weather.jpg" width=400; height=400>

### Objectives
- Use Kaggle dataset to make a weather prediction model.
- Prediction model will forecast the weather based on the temperature, humidity, wind speed, and precipitation.
- Prediction for 10 cities.
- Utilize Logistic Regression.
- Evaluate model using SciKit-Learn's Cross Validation, Confusion Matrix, and Classification Report.
- Analyze feature importance using Random Forest.
- Forecast weather trends using historical data.
"""

# Commented out IPython magic to ensure Python compatibility.
# Import packages
# %matplotlib inline

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, cross_val_predict
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score
from sklearn.ensemble import RandomForestClassifier

"""<h3 style="color:green;">  Loading and Reading the Dataset </h3>

<h4 style="color:orange;"> Load the weather data and perform initial Exploratory Data Analysis (EDA) </h4>
"""

# loading dataset
df = pd.read_csv('data/weather_data.csv')
# Check data size
print(f"Number of rows: {df.shape[0]}, Number of columns: {df.shape[1]}")
# display the first five rows of the dataset
df.head()

"""<h2 style="color:green;">  Overview of Dataset </h2>

<h4 style="color:orange;"> Understand the structure and characteristics of the dataset
"""

# Checking information of each column and data type
print(df.info())

# Check for mising values
print(df.isnull().sum())

# returns the number of unique variables for each column
print(df.nunique())

# Potential outliers in features like Temperature
plt.hist(df['Temperature_C'], bins=30, color='blue')
plt.title('Distribution of Temperature')
plt.xlabel('Temperature (°C)')
plt.ylabel('Frequency')
plt.show()

"""<h3 style="color:green;"> Description of Features </h3>

<h4 style="color:orange;"> Understand the descriptive statistics of the features
"""

# Statistics of Data
print(df.describe())

# Statistics of specific column ex: Location
print(df['Location'].value_counts())

# check unique locations
print(df['Location'].unique())

"""<h2 style="color:green;"> Data Cleaning and Preprocessing

<h4 style="color:orange;">  Prepare data for ML by extracting features and creating target variable

### Analyzing Data Overtime
"""

# Converting Date_Time column to a datetime format
df['Date_Time'] = pd.to_datetime(df['Date_Time'])

# extracting year, month, and day from Date_Time
df['Year'] = df['Date_Time'].dt.year
df['Month'] = df['Date_Time'].dt.month
df['Day'] = df['Date_Time'].dt.day

# Function to classify weather conditions (create target column)
# define a rule-based approach to categorize weather conditions

def classify_weather(row):
    """
    Classify weather conditions based on different parameters:
     - Storming: High precipitation and wind speed
     - Snowing: Negative temperature with precipitation
     - Raining: Precipitation between 1mm and 10mm
     - Drizzle: Low precipitation and high humidity
     - Foggy: High humidity and low wind speed
     - Windy: High wind speed
     - Sunny: Low humidity and high temperature
     - Cloudy: Default condition
    """
    if row['Precipitation_mm'] > 10 and row['Wind_Speed_kmh'] > 30:
        return 'Storming'
    elif row['Temperature_C'] < 0 and row['Precipitation_mm'] > 0:
        return 'Snowing'
    elif row['Precipitation_mm'] > 1 and row['Precipitation_mm'] <= 10:
        return 'Raining'
    elif row['Precipitation_mm'] > 0 and row['Humidity_pct'] > 80:
        return 'Drizzle'
    elif row['Humidity_pct'] > 90 and row['Temperature_C'] > 0 and row['Wind_Speed_kmh'] < 15:
        return 'Foggy'
    elif row['Wind_Speed_kmh'] > 40:
        return 'Windy'
    elif row['Humidity_pct'] < 50 and row['Temperature_C'] > 20:
        return 'Sunny'
    else:
        return 'Cloudy'


# Create a new target variable for weather conditions
df['Weather_Condition'] = df.apply(classify_weather, axis=1)
print(df['Weather_Condition'].value_counts())


df.head() # prints the first 5 rows
#df.tail() # prints the last 5 rows

print(df.info())

"""<h2 style="color:green;">  Analyzing each column

<h4 style="color:orange;"> Visualizing Weather Conditions

"""

# weather conditions by location
sns.countplot(data=df, x='Location', hue='Weather_Condition', palette='Set2')
plt.title('Weather Conditions by Location')
plt.xticks(rotation=45)
plt.show()

"""### Analyzing Average Temperature

<h3 style="color:green;"> Temperature
"""

plt.hist(df['Temperature_C'], bins=30, color='skyblue')
plt.title('Distribution of Temperature')
plt.xlabel('Temperature_C')
plt.ylabel('Frequency')
plt.show()

"""<h3 style="color:green;"> Time Series Analysis

<h4 style="color:orange;"> Setting Date_Time as an index
"""

# now set Date_Time as index
df.set_index('Date_Time', inplace=True)

# Daily Average Temperature
# Looking at average temperature on graph
daily_avg_temp = df.resample('D')['Temperature_C'].mean()

plt.figure(figsize=(14, 6))
plt.plot(daily_avg_temp, color='tomato')
plt.title('Daily Average Temperature')
plt.xlabel('Date')
plt.ylabel('Temperature (°C)')
plt.xticks(rotation=45)
plt.show()

"""### Analyzing Average Humidity"""

# Daily Average Humidity
# Looking at average humidity
daily_avg_humidity = df.resample('D')['Humidity_pct'].mean()

plt.figure(figsize=(14, 6))
plt.plot(daily_avg_humidity, color='blue')
plt.title('Daily Average Humidity')
plt.xlabel('Date')
plt.ylabel('Humidity (%)')
plt.xticks(rotation=45)
plt.show()

"""### Analyzing Average Precipitation"""

# Daily Average Precipitation
# Looking at average precipitation on graph
daily_avg_perceipitation = df.resample('D')['Precipitation_mm'].mean()

plt.figure(figsize=(14, 6))
plt.plot(daily_avg_temp, color='green')
plt.title('Daily Average Precipitation')
plt.xlabel('Date')
plt.ylabel('Precipitation (mm)')
plt.xticks(rotation=45)
plt.show()

"""### Analyzing Average Wind Speed"""

# Daily Average Wind Speed
# Looking at average Wind_Speed on graph
daily_avg_Wind_Speed = df.resample('D')['Wind_Speed_kmh'].mean()

plt.figure(figsize=(14, 6))
plt.plot(daily_avg_temp, color='purple')
plt.title('Daily Average Wind Speed')
plt.xlabel('Date')
plt.ylabel('Wind Speed (kmh)')
plt.xticks(rotation=45)
plt.show()

"""### Encoding Categirical Variables using One-Hot Encoding"""

print(df.columns)

# https://builtin.com/articles/one-hot-encoding
# https://www.c-sharpcorner.com/article/a-beginners-guide-to-one-hot-encoding-using-pandas-getdummies-method/

"""<h2 style="color:green;"> Defining Features and Target Values"""

X = df[['Temperature_C', 'Humidity_pct', 'Precipitation_mm', 'Wind_Speed_kmh']]
y = df['Weather_Condition']

# Check the shapes of X and y
# print('The X.shape of the data is:', X.shape)
# print('The y.shape of the data is:', y.shape)

"""#### Split the Data into Training and Testing Sets"""

# Split data BEFORE scaling
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Scale features with StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""<h5>  Displaying the Shape of the Data after splitting it into Training and Testing sets"""

# Shape of training data
print('X_train_scaled Shape:', X_train_scaled.shape)
print('y_train Shape:', y_train.shape)

# Shape of testing data
print('X_test_scaled Shape:', X_test_scaled.shape)
print('y_test Shape:', y_test.shape)

"""<h2 style="color:green;"> Training the Logistic Regression Model

<h4 style="color:orange;"> Multiclass classification of weather conditions
"""

log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=2000, random_state=42)
log_reg.fit(X_train_scaled, y_train)

# predict on test set
y_pred = log_reg.predict(X_test_scaled)

# evaluate classification report
print("Classification Report (Test Set):")
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=log_reg.classes_, yticklabels=log_reg.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix on Test Set')
plt.show()

# cross validation for prediction & eval
# ensuring the model perfromance is consistent across different data splits
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
accuracies = []

# Perform manual cross-validation
for train_idx, test_idx in kf.split(X, y):

    # Split the data into training and test sets for this fold
    X_train_fold, X_test_fold = X.iloc[train_idx], X.iloc[test_idx]
    y_train_fold, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]

    # Scale the data for this fold
    scaler = StandardScaler()
    X_train_fold_scaled = scaler.fit_transform(X_train_fold)
    X_test_fold_scaled = scaler.transform(X_test_fold)

    # Train and evaluate the model
    cv_log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=2000, random_state=42)
    cv_log_reg.fit(X_train_fold_scaled, y_train_fold)
    y_pred_fold = cv_log_reg.predict(X_test_fold_scaled)
    accuracies.append(accuracy_score(y_test_fold, y_pred_fold))

print(f"Cross Validation Accuracy: {accuracies}")
print(f"Mean Cross Validation Accuracy: {np.mean(accuracies):.4f}")

# PREDICTIONS ACROSS ALL FOLDS
# Create a pipeline for scaling and logistic regression
## A pipeline is a sequential workflow that automates the application of preprocessing steps (like scaling) and model training or prediction, ensuring consistent and efficient data processing.
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('log_reg', LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=2000, random_state=42))
])

y_pred_cv = cross_val_predict(pipeline, X, y, cv=kf, method = 'predict')

# confusion matrix for cross validation (for storming or not)
cm_cv = confusion_matrix(y, y_pred_cv)
sns.heatmap(cm_cv, annot=True, fmt='d', cmap='Blues', xticklabels=log_reg.classes_, yticklabels=log_reg.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix (Cross Validation)')
plt.show()

# classification report for cross validation
print("Classification Report (Cross Validation):")
print(classification_report(y, y_pred_cv))

# Area under the curve

# Define pipeline for scaling and logistic regression
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('log_reg', LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=2000, random_state=42))
])

# Cross-validation setup
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Predict probabilities using cross-validation
y_pred_proba_cv = cross_val_predict(pipeline, X, y, cv=kf, method='predict_proba')

# Compute AUC score
auc_cv = roc_auc_score(y, y_pred_proba_cv, multi_class='ovr',average='macro')
print(f"Cross Validation Area Under the Curve: {auc_cv:.4f}")

"""AUC Score: 0.9520
- This high score indicates that the model performs well at distinguishing between classes.
- The model assigns high probabilities to the correct classes most of the time.
- *Macro Averaging* ensures that the performance across all classes is considered equally, making this metric fair even for imbalanced datasets.

<h3 style="color:green;">  Feature Importance Random Forest
<h4 style="color:orange;"> Understand which feature drives the weather predictions
"""

# training random forest model
rf_model = RandomForestClassifier(n_estimators = 100, random_state = 42)
rf_model.fit(X_train_scaled, y_train)

# extract feature importances
rf_feature_imp = rf_model.feature_importances_
feature_imp_df = pd.DataFrame({'Feature': X.columns, 'Importance': rf_feature_imp}).sort_values(by='Importance', ascending = False)

# plot feature importances
plt.figure(figsize = (6,4))
sns.barplot(data = feature_imp_df, x='Importance', y='Feature', palette='viridis')
plt.title('Feature Importance (Random Forest)')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()

# feature importance
print("Feature Importance (Random Forest):")
print(feature_imp_df)

# random forest accuracy
accuracy = rf_model.score(X_test_scaled, y_test)
print(f"Random Forest Accuracy: {accuracy: .2f}")

"""- The feature importance plot shows that `Temperature_C` is the most significant predictor of all the features in the Random Forest Model. The importance value for Temperature_C is 0.688, which is higher than Precipitation_mm, Humidity_pct, and Wind_Speed_kmh. This indicates that changes in temperature play the largest role in the predicted weather condition.

- `Precipitation_mm` of 0.2611 is the second most important feature. This makes sense since precipitation levels are crucial for conditions like raining or snowing.

- `Humidity_pct` of 0.051 plays a smaller role compared to temperature and precipitation, but influences predictions like drizzle.

- `Wind_Speed_kmh` of 0.000065 has almost no importance and does not contribute to predicting weather conditions.

<h2 style="color:green;"> K-nearest neighbors (KNN) Comparison
<h4 style="color:orange;"> Compare performance with KNN ML Algorithm
"""

# KNN comparison
from sklearn.neighbors import KNeighborsClassifier

# initialize model
knn_model = KNeighborsClassifier(n_neighbors=5)

# fit model
knn_model.fit(X_train_scaled, y_train)

# evaluate accuracy
accuracy = knn_model.score(X_test_scaled, y_test)
print(f"KNN Accuracy: {accuracy:.2f}")

"""<h3 style="color:green;"> Logistic Regression Coefficients"""

# analyzing the weights assigned by the logistic regression model
log_reg_coefficients = pd.DataFrame(log_reg.coef_, columns = X.columns, index=log_reg.classes_)

# plot coefficients
log_reg_coefficients.T.plot(kind='bar', figsize=(6,4))
plt.title('Logistic Regression Coefficient by Class')
plt.xlabel('Features')
plt.ylabel('Coefficient Value')
plt.xticks(rotation=45)
plt.legend(title='Weather Condition', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

print("Logestic Regression Coefficients:")
print(log_reg_coefficients)

"""<h3 style="color:green;"> Predicting Future Weather Conditions

<h4 style="color:orange;"> Model's ability to predict weather conditions for new data points
"""

# creating a sample dataset for future predictions
future_data = pd.DataFrame({
    'Temperature_C': [20, -10, 15, 25],
    'Humidity_pct': [40, 85, 95, 30],
    'Precipitation_mm': [0, 5, 12, 1],
    'Wind_Speed_kmh': [10, 50, 5, 15],
})

# scale future data
future_data_scaled = scaler.transform(future_data)

# predict using Logistic Regression
future_predictions = log_reg.predict(future_data_scaled)

# predicted probabilities for each class
future_proba = log_reg.predict_proba(future_data_scaled)

# adding predictions to the original future data
future_data['Predicted_Weather'] = future_predictions

# show predictions
print(future_data)

# probabilities for each class, creating a df for predicted probabilities for each weather condition
proba_df = pd.DataFrame(future_proba, columns=log_reg.classes_)
print(proba_df)

# plotting class distribution
plt.figure(figsize=(6,4))
sns.countplot(data=df, x='Weather_Condition', order=df['Weather_Condition'].value_counts().index, palette='Set2')
plt.title('Class Distribution of Weather Conditions')
plt.xticks(rotation=45)
plt.xlabel('Weather Condition')
plt.ylabel('Count')
plt.show()

# classification report macro and weighted averaging (test set)
report = classification_report(y_test, y_pred, target_names=log_reg.classes_, output_dict=True)
df_report = pd.DataFrame(report).T
print(df_report)

# predicting long term trends using historical data
num_columns = ['Temperature_C', 'Humidity_pct', 'Precipitation_mm', 'Wind_Speed_kmh']
# resample for monthly averages
monthly_avg = df[num_columns].resample('M').mean()

# plotting the trends
plt.figure(figsize=(6,4))
plt.plot(monthly_avg.index, monthly_avg['Temperature_C'], label='Temperature (C)', color='tomato')
plt.plot(monthly_avg.index, monthly_avg['Humidity_pct'], label='Humidity (%)', color='blue')
plt.plot(monthly_avg.index, monthly_avg['Precipitation_mm'], label='Precipitation (mm)', color='green')
plt.plot(monthly_avg.index, monthly_avg['Wind_Speed_kmh'], label='Wind Speed (km/h)', color='purple')

plt.title('Monthly Average Weather Trends')
plt.xlabel('Date')
plt.xticks(rotation=45)
plt.ylabel('Values')
plt.legend()
plt.grid()
plt.show()

# Which variables are the most predicted one, irrelevant or not, predict future

"""## Other Visualizations"""

#### the rest of this is from chat, thought it was interesting to see diff visualizations

import plotly.express as px

fig = px.line(monthly_avg, x=monthly_avg.index, y='Temperature_C', title="Monthly Temperature Trends")
fig.show()

import plotly.express as px

# Interactive time series plot
fig = px.line(monthly_avg, x=monthly_avg.index,
              y=['Temperature_C', 'Humidity_pct', 'Precipitation_mm'],
              labels={'value': 'Weather Metrics', 'index': 'Date'},
              title='Monthly Weather Trends')
fig.update_traces(mode='lines+markers')
fig.show()

cm = confusion_matrix(y_test, y_pred)
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

plt.figure(figsize=(8, 6))
sns.heatmap(cm_normalized, annot=True, fmt=".2%", cmap='coolwarm', xticklabels=log_reg.classes_, yticklabels=log_reg.classes_)
plt.title('Confusion Matrix with Percentages')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

condition_counts = df['Weather_Condition'].value_counts()
plt.figure(figsize=(8, 8))
plt.pie(condition_counts, labels=condition_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette("Set3", len(condition_counts)))
plt.title("Weather Condition Distribution")
plt.show()

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc

y_test_binarized = label_binarize(y_test, classes=log_reg.classes_)
y_pred_proba = log_reg.predict_proba(X_test_scaled)

plt.figure(figsize=(8, 6))
for i, class_label in enumerate(log_reg.classes_):
    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_pred_proba[:, i])
    plt.plot(fpr, tpr, label=f'{class_label} (AUC: {auc(fpr, tpr):.2f})')

plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')
plt.title('One-vs-Rest ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

fig = px.scatter(df, x='Temperature_C', y='Humidity_pct', color='Weather_Condition',
                 size='Precipitation_mm', hover_data=['Location'],
                 title='Weather Conditions Based on Temperature and Humidity')
fig.show()

city_avg = df.groupby(['Location', pd.Grouper(freq='M')])['Temperature_C'].mean().unstack(level=0)
city_avg.plot(figsize=(12, 6), colormap='tab10')
plt.title('Monthly Temperature Trends by City')
plt.xlabel('Date')
plt.ylabel('Average Temperature (°C)')
plt.legend(title='City')
plt.show()